{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Project Unit Test\n",
    "\n",
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from playground import execute_dsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "1. ``drop``: Deletes a column or a row in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tables:\n",
      "table1\n",
      "   col1  col2  col3\n",
      "0     1     6    11\n",
      "1     2     7    12\n",
      "2     3     8    13\n",
      "3     4     9    14\n",
      "4     5    10    15\n",
      "modified tables:\n",
      "table1\n",
      "   col2  col3\n",
      "0     6    11\n",
      "1     7    12\n",
      "2     8    13\n",
      "3     9    14\n",
      "4    10    15\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.DataFrame(\n",
    "    {\n",
    "        \"col1\": [1, 2, 3, 4, 5],\n",
    "        \"col2\": [6, 7, 8, 9, 10],\n",
    "        \"col3\": [11, 12, 13, 14, 15],\n",
    "    }\n",
    ")\n",
    "tables = {\n",
    "    \"table1\": table1,\n",
    "}\n",
    "\n",
    "dsl_code = \"\"\"\n",
    "    drop(table=table1, label=col1, axis=1)\n",
    "\"\"\"\n",
    "\n",
    "print(\"original tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)\n",
    "tables = execute_dsl(tables, dsl_code)\n",
    "print(\"modified tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tables:\n",
      "table1\n",
      "   col1  col2  col3\n",
      "0     1     6    11\n",
      "1     2     7    12\n",
      "2     3     8    13\n",
      "3     4     9    14\n",
      "4     5    10    15\n",
      "modified tables:\n",
      "table1\n",
      "   col1  col2  col3\n",
      "0     1     6    11\n",
      "1     2     7    12\n",
      "3     4     9    14\n",
      "4     5    10    15\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.DataFrame(\n",
    "    {\n",
    "        \"col1\": [1, 2, 3, 4, 5],\n",
    "        \"col2\": [6, 7, 8, 9, 10],\n",
    "        \"col3\": [11, 12, 13, 14, 15],\n",
    "    }\n",
    ")\n",
    "tables = {\n",
    "    \"table1\": table1,\n",
    "}\n",
    "\n",
    "dsl_code = \"\"\"\n",
    "    drop(table=table1, label=2, axis=0)\n",
    "\"\"\"\n",
    "print(\"original tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)\n",
    "execute_dsl(tables, dsl_code)\n",
    "print(\"modified tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ``move``: Relocates a column from one position to another in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tables:\n",
      "table1\n",
      "   col1  col2  col3\n",
      "0     1     6    11\n",
      "1     2     7    12\n",
      "2     3     8    13\n",
      "3     4     9    14\n",
      "4     5    10    15\n",
      "modified tables:\n",
      "table1\n",
      "   col2  col3  col1\n",
      "0     6    11     1\n",
      "1     7    12     2\n",
      "2     8    13     3\n",
      "3     9    14     4\n",
      "4    10    15     5\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.DataFrame(\n",
    "    {\n",
    "        \"col1\": [1, 2, 3, 4, 5],\n",
    "        \"col2\": [6, 7, 8, 9, 10],\n",
    "        \"col3\": [11, 12, 13, 14, 15],\n",
    "    }\n",
    ")\n",
    "tables = {\n",
    "    \"table1\": table1,\n",
    "}\n",
    "\n",
    "dsl_code = \"\"\"\n",
    "    move(table=table1, label=col1, target_table=table1, target_label=2, axis=columns)\n",
    "\"\"\"\n",
    "\n",
    "print(\"original tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)\n",
    "execute_dsl(tables, dsl_code)\n",
    "print(\"modified tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tables:\n",
      "table1\n",
      "   col1  col2  col3\n",
      "0     1     6    11\n",
      "1     2     7    12\n",
      "2     3     8    13\n",
      "3     4     9    14\n",
      "4     5    10    15\n",
      "modified tables:\n",
      "table1\n",
      "   col1  col2  col3\n",
      "0     1     6    11\n",
      "2     3     8    13\n",
      "1     2     7    12\n",
      "3     4     9    14\n",
      "4     5    10    15\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.DataFrame(\n",
    "    {\n",
    "        \"col1\": [1, 2, 3, 4, 5],\n",
    "        \"col2\": [6, 7, 8, 9, 10],\n",
    "        \"col3\": [11, 12, 13, 14, 15],\n",
    "    }\n",
    ")\n",
    "tables = {\n",
    "    \"table1\": table1,\n",
    "}\n",
    "\n",
    "dsl_code = \"\"\"\n",
    "    move(table=table1, label=1, target_table=table1, target_label=2, axis=index)\n",
    "\"\"\"\n",
    "\n",
    "print(\"original tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)\n",
    "execute_dsl(tables, dsl_code)\n",
    "print(\"modified tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ``copy``: Duplicates a column and append the copied column to the end of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tables:\n",
      "table1\n",
      "   col1  col2  col3\n",
      "0     1     6    11\n",
      "1     2     7    12\n",
      "2     3     8    13\n",
      "3     4     9    14\n",
      "4     5    10    15\n",
      "modified tables:\n",
      "table1\n",
      "   col1  col2  col3  col4\n",
      "0     1     6    11    11\n",
      "1     2     7    12    12\n",
      "2     3     8    13    13\n",
      "3     4     9    14    14\n",
      "4     5    10    15    15\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.DataFrame(\n",
    "    {\n",
    "        \"col1\": [1, 2, 3, 4, 5],\n",
    "        \"col2\": [6, 7, 8, 9, 10],\n",
    "        \"col3\": [11, 12, 13, 14, 15],\n",
    "    }\n",
    ")\n",
    "tables = {\n",
    "    \"table1\": table1,\n",
    "}\n",
    "\n",
    "dsl_code = \"\"\"\n",
    "    copy(table=table1, label=col3, target_table=table1, target_label=col4, axis=columns)\n",
    "\"\"\"\n",
    "\n",
    "print(\"original tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)\n",
    "execute_dsl(tables, dsl_code)\n",
    "print(\"modified tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tables:\n",
      "table1\n",
      "   col1  col2  col3\n",
      "0     1     6    11\n",
      "1     2     7    12\n",
      "2     3     8    13\n",
      "3     4     9    14\n",
      "4     5    10    15\n",
      "modified tables:\n",
      "table1\n",
      "   col1  col2  col3\n",
      "0     1     6    11\n",
      "1     2     7    12\n",
      "2     3     8    13\n",
      "3     4     9    14\n",
      "4     5    10    15\n",
      "5     5    10    15\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.DataFrame(\n",
    "    {\n",
    "        \"col1\": [1, 2, 3, 4, 5],\n",
    "        \"col2\": [6, 7, 8, 9, 10],\n",
    "        \"col3\": [11, 12, 13, 14, 15],\n",
    "    }\n",
    ")\n",
    "tables = {\n",
    "    \"table1\": table1,\n",
    "}\n",
    "\n",
    "dsl_code = \"\"\"\n",
    "    copy(table=table1, label=4, target_table=table1, target_label=5, axis=index)\n",
    "\"\"\"\n",
    "\n",
    "print(\"original tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)\n",
    "execute_dsl(tables, dsl_code)\n",
    "print(\"modified tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ``merge``: Concatenates two columns and append the merged column to the end of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tables:\n",
      "table1\n",
      "  first_name last_name  ages\n",
      "0      Alice     Smith    25\n",
      "1        Bob   Johnson    30\n",
      "2    Charlie  Williams    35\n",
      "3      David     Jones    40\n",
      "4        Eve     Brown    45\n",
      "modified tables:\n",
      "table1\n",
      "  first_name last_name  ages              name\n",
      "0      Alice     Smith    25       Alice Smith\n",
      "1        Bob   Johnson    30       Bob Johnson\n",
      "2    Charlie  Williams    35  Charlie Williams\n",
      "3      David     Jones    40       David Jones\n",
      "4        Eve     Brown    45         Eve Brown\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.DataFrame(\n",
    "    {\n",
    "        \"first_name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "        \"last_name\": [\"Smith\", \"Johnson\", \"Williams\", \"Jones\", \"Brown\"],\n",
    "        \"ages\": [25, 30, 35, 40, 45],\n",
    "    }\n",
    ")\n",
    "tables = {\n",
    "    \"table1\": table1,\n",
    "}\n",
    "\n",
    "dsl_code = \"\"\"\n",
    "    merge(table=table1, label_1=first_name, label_2=last_name, glue=\" \", new_label=name, axis=columns)\n",
    "\"\"\"\n",
    "\n",
    "print(\"original tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)\n",
    "execute_dsl(tables, dsl_code)\n",
    "print(\"modified tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tables:\n",
      "table1\n",
      "  first_name last_name  ages\n",
      "0      Alice     Smith    25\n",
      "1        Bob   Johnson    30\n",
      "2    Charlie  Williams    35\n",
      "3      David     Jones    40\n",
      "4        Eve     Brown    45\n",
      "modified tables:\n",
      "table1\n",
      "  first_name      last_name   ages\n",
      "0      Alice          Smith     25\n",
      "1        Bob        Johnson     30\n",
      "2    Charlie       Williams     35\n",
      "3      David          Jones     40\n",
      "4        Eve          Brown     45\n",
      "5  Alice Bob  Smith Johnson  25 30\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.DataFrame(\n",
    "    {\n",
    "        \"first_name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "        \"last_name\": [\"Smith\", \"Johnson\", \"Williams\", \"Jones\", \"Brown\"],\n",
    "        \"ages\": [25, 30, 35, 40, 45],\n",
    "    }\n",
    ")\n",
    "tables = {\n",
    "    \"table1\": table1,\n",
    "}\n",
    "\n",
    "dsl_code = \"\"\"\n",
    "    merge(table=table1, label_1=0, label_2=1, glue=\" \", new_label=5, axis=index)\n",
    "\"\"\"\n",
    "\n",
    "print(\"original tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)\n",
    "execute_dsl(tables, dsl_code)\n",
    "print(\"modified tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ``split``: Separates a column into two or more halves at the occurrences of the delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tables:\n",
      "table1\n",
      "               name  ages\n",
      "0       Alice Smith    25\n",
      "1       Bob Johnson    30\n",
      "2  Charlie Williams    35\n",
      "3       David Jones    40\n",
      "4         Eve Brown    45\n",
      "modified tables:\n",
      "table1\n",
      "   ages first_name last_name\n",
      "0    25      Alice     Smith\n",
      "1    30        Bob   Johnson\n",
      "2    35    Charlie  Williams\n",
      "3    40      David     Jones\n",
      "4    45        Eve     Brown\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice Smith\", \"Bob Johnson\", \"Charlie Williams\", \"David Jones\", \"Eve Brown\"],\n",
    "        \"ages\": [25, 30, 35, 40, 45],\n",
    "    }\n",
    ")\n",
    "tables = {\n",
    "    \"table1\": table1,\n",
    "}\n",
    "\n",
    "dsl_code = \"\"\"\n",
    "    split(table=table1, label=name, delimiter=\" \", new_labels=[first_name, last_name], axis=columns)\n",
    "\"\"\"\n",
    "\n",
    "print(\"original tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)\n",
    "execute_dsl(tables, dsl_code)\n",
    "print(\"modified tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. ``fold``: Collapses all columns after a specific column into one column in the output table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "  command\t{'fold': {'table': Token('NAME', 'table1'), 'column': Tree(Token('RULE', 'label'), [Token('NAME', 'a')])}}\n",
      "\n",
      "Executing command: Tree(Token('RULE', 'command'), [{'fold': {'table': Token('NAME', 'table1'), 'column': Tree(Token('RULE', 'label'), [Token('NAME', 'a')])}}])\n",
      "Table before column split:\n",
      "     a   b   c\n",
      "0  a1  b1  c1\n",
      "1  a2  b2  c2\n",
      "2  a3  b3  c3\n",
      "Table after column split:\n",
      "     a folded_value\n",
      "0  a1           b1\n",
      "1  a1           c1\n",
      "2  a2           b2\n",
      "3  a2           c2\n",
      "4  a3           b3\n",
      "5  a3           c3\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": [\"a1\", \"a2\", \"a3\"],\n",
    "        \"b\": [\"b1\", \"b2\", \"b3\"],\n",
    "        \"c\": [\"c1\", \"c2\", \"c3\"],\n",
    "    }\n",
    ")\n",
    "tables = {\n",
    "    \"table1\": table1,\n",
    "}\n",
    "\n",
    "dsl_code = \"\"\"\n",
    "    fold(table=table1, column=a)\n",
    "\"\"\"\n",
    "\n",
    "execute_dsl(tables, dsl_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. ``unfold``: \"Unflatten\" tables and move information from data values to column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnexpectedToken",
     "evalue": "Unexpected token Token('NAME', 'unfold') at line 2, column 5.\nExpected one of: \n\t* \"drop(\"\n\t* \"transpose(\"\n\t* \"copy(\"\n\t* \"test(\"\n\t* \"aggregate(\"\n\t* \"merge(\"\n\t* \"move(\"\n\t* \"split(\"\nPrevious tokens: [None]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedCharacters\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/clean/lib/python3.10/site-packages/lark/lexer.py:665\u001b[0m, in \u001b[0;36mContextualLexer.lex\u001b[0;34m(self, lexer_state, parser_state)\u001b[0m\n\u001b[1;32m    664\u001b[0m         lexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexers[parser_state\u001b[38;5;241m.\u001b[39mposition]\n\u001b[0;32m--> 665\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mlexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/clean/lib/python3.10/site-packages/lark/lexer.py:598\u001b[0m, in \u001b[0;36mBasicLexer.next_token\u001b[0;34m(self, lex_state, parser_state)\u001b[0m\n\u001b[1;32m    597\u001b[0m         allowed \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<END-OF-FILE>\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedCharacters(lex_state\u001b[38;5;241m.\u001b[39mtext, line_ctr\u001b[38;5;241m.\u001b[39mchar_pos, line_ctr\u001b[38;5;241m.\u001b[39mline, line_ctr\u001b[38;5;241m.\u001b[39mcolumn,\n\u001b[1;32m    599\u001b[0m                                allowed\u001b[38;5;241m=\u001b[39mallowed, token_history\u001b[38;5;241m=\u001b[39mlex_state\u001b[38;5;241m.\u001b[39mlast_token \u001b[38;5;129;01mand\u001b[39;00m [lex_state\u001b[38;5;241m.\u001b[39mlast_token],\n\u001b[1;32m    600\u001b[0m                                state\u001b[38;5;241m=\u001b[39mparser_state, terminals_by_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminals_by_name)\n\u001b[1;32m    602\u001b[0m value, type_ \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mUnexpectedCharacters\u001b[0m: No terminal matches 'u' in the current parser context, at line 2 col 5\n\n    unfold(table=table1)\n    ^\nExpected one of: \n\t* \"drop(\"\n\t* \"transpose(\"\n\t* \"test(\"\n\t* \"copy(\"\n\t* \"aggregate(\"\n\t* \"merge(\"\n\t* \"move(\"\n\t* \"split(\"\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnexpectedToken\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m      7\u001b[0m tables \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable1\u001b[39m\u001b[38;5;124m\"\u001b[39m: table1,\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     11\u001b[0m dsl_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m    unfold(table=table1)\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mexecute_dsl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdsl_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data02/xhq/test/dango-backend/dsl/playground.py:138\u001b[0m, in \u001b[0;36mexecute_dsl\u001b[0;34m(tables, dsl_code)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_dsl\u001b[39m(tables, dsl_code):\n\u001b[0;32m--> 138\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m \u001b[43mdsl_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsl_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# print(parsed.pretty())  # This line prints the parsed tree in a readable format.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m command \u001b[38;5;129;01min\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mchildren:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# print(\"Executing command:\", command)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/clean/lib/python3.10/site-packages/lark/lark.py:658\u001b[0m, in \u001b[0;36mLark.parse\u001b[0;34m(self, text, start, on_error)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, start: Optional[\u001b[38;5;28mstr\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, on_error: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOptional[Callable[[UnexpectedInput], bool]]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParseTree\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    641\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse the given text, according to the options provided.\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \n\u001b[1;32m    643\u001b[0m \u001b[38;5;124;03m    Parameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    656\u001b[0m \n\u001b[1;32m    657\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/clean/lib/python3.10/site-packages/lark/parser_frontends.py:104\u001b[0m, in \u001b[0;36mParsingFrontend.parse\u001b[0;34m(self, text, start, on_error)\u001b[0m\n\u001b[1;32m    102\u001b[0m kw \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m on_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_error\u001b[39m\u001b[38;5;124m'\u001b[39m: on_error}\n\u001b[1;32m    103\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_lexer_thread(text)\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchosen_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/clean/lib/python3.10/site-packages/lark/parsers/lalr_parser.py:42\u001b[0m, in \u001b[0;36mLALR_Parser.parse\u001b[0;34m(self, lexer, start, on_error)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, lexer, start, on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m UnexpectedInput \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m on_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/clean/lib/python3.10/site-packages/lark/parsers/lalr_parser.py:88\u001b[0m, in \u001b[0;36m_Parser.parse\u001b[0;34m(self, lexer, start, value_stack, state_stack, start_interactive)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_interactive:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InteractiveParser(\u001b[38;5;28mself\u001b[39m, parser_state, parser_state\u001b[38;5;241m.\u001b[39mlexer)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_from_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/clean/lib/python3.10/site-packages/lark/parsers/lalr_parser.py:111\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[0;34m(self, state, last_token)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug:\n",
      "File \u001b[0;32m~/miniconda3/envs/clean/lib/python3.10/site-packages/lark/parsers/lalr_parser.py:100\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[0;34m(self, state, last_token)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     token \u001b[38;5;241m=\u001b[39m last_token\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m state\u001b[38;5;241m.\u001b[39mlexer\u001b[38;5;241m.\u001b[39mlex(state):\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         state\u001b[38;5;241m.\u001b[39mfeed_token(token)\n",
      "File \u001b[0;32m~/miniconda3/envs/clean/lib/python3.10/site-packages/lark/lexer.py:674\u001b[0m, in \u001b[0;36mContextualLexer.lex\u001b[0;34m(self, lexer_state, parser_state)\u001b[0m\n\u001b[1;32m    672\u001b[0m     last_token \u001b[38;5;241m=\u001b[39m lexer_state\u001b[38;5;241m.\u001b[39mlast_token  \u001b[38;5;66;03m# Save last_token. Calling root_lexer.next_token will change this to the wrong token\u001b[39;00m\n\u001b[1;32m    673\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_lexer\u001b[38;5;241m.\u001b[39mnext_token(lexer_state, parser_state)\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedToken(token, e\u001b[38;5;241m.\u001b[39mallowed, state\u001b[38;5;241m=\u001b[39mparser_state, token_history\u001b[38;5;241m=\u001b[39m[last_token], terminals_by_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_lexer\u001b[38;5;241m.\u001b[39mterminals_by_name)\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UnexpectedCharacters:\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mUnexpectedToken\u001b[0m: Unexpected token Token('NAME', 'unfold') at line 2, column 5.\nExpected one of: \n\t* \"drop(\"\n\t* \"transpose(\"\n\t* \"copy(\"\n\t* \"test(\"\n\t* \"aggregate(\"\n\t* \"merge(\"\n\t* \"move(\"\n\t* \"split(\"\nPrevious tokens: [None]\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": [\"a1\", \"a1\", \"a2\", \"a2\", \"a3\", \"a3\"],\n",
    "        \"b\": [\"b1\", \"c1\", \"b2\", \"c2\", \"b3\", \"c3\"],\n",
    "    }\n",
    ")\n",
    "tables = {\n",
    "    \"table1\": table1,\n",
    "}\n",
    "\n",
    "dsl_code = \"\"\"\n",
    "    unfold(table=table1)\n",
    "\"\"\"\n",
    "\n",
    "execute_dsl(tables, dsl_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. ``transpose``: Transpose the rows and columns of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tables:\n",
      "table1\n",
      "    a   b   c\n",
      "0  a1  b1  c1\n",
      "1  a2  b2  c2\n",
      "2  a3  b3  c3\n",
      "modified tables:\n",
      "table1\n",
      "    0   1   2\n",
      "a  a1  a2  a3\n",
      "b  b1  b2  b3\n",
      "c  c1  c2  c3\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": [\"a1\", \"a2\", \"a3\"],\n",
    "        \"b\": [\"b1\", \"b2\", \"b3\"],\n",
    "        \"c\": [\"c1\", \"c2\", \"c3\"],\n",
    "    }\n",
    ")\n",
    "tables = {\n",
    "    \"table1\": table1,\n",
    "}\n",
    "\n",
    "dsl_code = \"\"\"\n",
    "    transpose(table=table1)\n",
    "\"\"\"\n",
    "\n",
    "print(\"original tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)\n",
    "execute_dsl(tables, dsl_code)\n",
    "print(\"modified tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. `aggregate`: Aggregate the data in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tables:\n",
      "table1\n",
      "   a  b  c\n",
      "0  1  4  7\n",
      "1  2  5  8\n",
      "2  3  6  9\n",
      "modified tables:\n",
      "table1\n",
      "   var  median  mean   prod   sum  max  std  min\n",
      "0  9.0     4.0   4.0   28.0  12.0  7.0  3.0  1.0\n",
      "1  9.0     5.0   5.0   80.0  15.0  8.0  3.0  2.0\n",
      "2  9.0     6.0   6.0  162.0  18.0  9.0  3.0  3.0\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": [1, 2, 3],\n",
    "        \"b\": [4, 5, 6],\n",
    "        \"c\": [7, 8, 9],\n",
    "    }\n",
    ")\n",
    "tables = {\n",
    "    \"table1\": table1,\n",
    "}\n",
    "\n",
    "dsl_code = \"\"\"\n",
    "    aggregate(table=table1, functions=[mean, median, prod, sum, std, var, min, max], axis=columns)\n",
    "\"\"\"\n",
    "\n",
    "print(\"original tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)\n",
    "execute_dsl(tables, dsl_code)\n",
    "print(\"modified tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tables:\n",
      "table1\n",
      "   a  b  c\n",
      "0  1  4  7\n",
      "1  2  5  8\n",
      "2  3  6  9\n",
      "modified tables:\n",
      "table1\n",
      "          a      b      c\n",
      "var     1.0    1.0    1.0\n",
      "median  2.0    5.0    8.0\n",
      "mean    2.0    5.0    8.0\n",
      "prod    6.0  120.0  504.0\n",
      "sum     6.0   15.0   24.0\n",
      "max     3.0    6.0    9.0\n",
      "std     1.0    1.0    1.0\n",
      "min     1.0    4.0    7.0\n"
     ]
    }
   ],
   "source": [
    "table1 = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": [1, 2, 3],\n",
    "        \"b\": [4, 5, 6],\n",
    "        \"c\": [7, 8, 9],\n",
    "    }\n",
    ")\n",
    "tables = {\n",
    "    \"table1\": table1,\n",
    "}\n",
    "\n",
    "dsl_code = \"\"\"\n",
    "    aggregate(table=table1, functions=[mean, median, prod, sum, std, var, min, max], axis=index)\n",
    "\"\"\"\n",
    "\n",
    "print(\"original tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)\n",
    "execute_dsl(tables, dsl_code)\n",
    "print(\"modified tables:\")\n",
    "for name, table in tables.items():\n",
    "    print(name)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. `test`: Statistical tests for the data in the table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-cleaning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
